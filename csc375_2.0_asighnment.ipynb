{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.io import arff\n",
    "import sys \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import matplotlib.pyplot as plt #used to plot graphs\n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
    "from sklearn.cross_validation import KFold # use for cross validation\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "data = arff.loadarff('C:\\Anaconda3\\EEG_Eye_State.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for i in columns:\n",
    "    df[i] = df[i].astype('category')\n",
    "for i in columns:\n",
    "    df[i] = pd.Categorical(df[i]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>eyeDetection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "\n",
       "        P8       T8      FC6       F4       F8      AF4 eyeDetection  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85         b'0'  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10         b'0'  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23         b'0'  \n",
       "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41         b'0'  \n",
       "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46         b'0'  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display first 5 data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14980 entries, 0 to 14979\n",
      "Data columns (total 15 columns):\n",
      "AF3             14980 non-null float64\n",
      "F7              14980 non-null float64\n",
      "F3              14980 non-null float64\n",
      "FC5             14980 non-null float64\n",
      "T7              14980 non-null float64\n",
      "P7              14980 non-null float64\n",
      "O1              14980 non-null float64\n",
      "O2              14980 non-null float64\n",
      "P8              14980 non-null float64\n",
      "T8              14980 non-null float64\n",
      "FC6             14980 non-null float64\n",
      "F4              14980 non-null float64\n",
      "F8              14980 non-null float64\n",
      "AF4             14980 non-null float64\n",
      "eyeDetection    14980 non-null object\n",
      "dtypes: float64(14), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AF3             float64\n",
       "F7              float64\n",
       "F3              float64\n",
       "FC5             float64\n",
       "T7              float64\n",
       "P7              float64\n",
       "O1              float64\n",
       "O2              float64\n",
       "P8              float64\n",
       "T8              float64\n",
       "FC6             float64\n",
       "F4              float64\n",
       "F8              float64\n",
       "AF4             float64\n",
       "eyeDetection     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14980, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6',\n",
       "       'F4', 'F8', 'AF4', 'eyeDetection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are coloumns with missing values\n",
    "droping_list_all=[]\n",
    "for j in range(0,14):\n",
    "    if not df.iloc[:, j].notnull().all():\n",
    "        droping_list_all.append(j)        \n",
    "        #print(df.iloc[:,j].unique())\n",
    "droping_list_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for LSTM Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((14, len(df)))\n",
    "for i in range(len(df.columns)-1):\n",
    "    X[i] = np.array(df[df.columns[i]])\n",
    "X = X.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4329.23, 4009.23, 4289.23, ..., 4280.51, 4635.9 , 4393.85],\n",
       "        [4324.62, 4004.62, 4293.85, ..., 4279.49, 4632.82, 4384.1 ],\n",
       "        [4327.69, 4006.67, 4295.38, ..., 4282.05, 4628.72, 4389.23],\n",
       "        ...,\n",
       "        [4325.64, 4006.67, 4278.46, ..., 4266.67, 4622.05, 4380.51],\n",
       "        [4326.15, 4010.77, 4276.41, ..., 4273.85, 4627.18, 4389.74],\n",
       "        [4326.15, 4011.28, 4276.92, ..., 4277.95, 4637.44, 4393.33]],\n",
       "\n",
       "       [[4324.62, 4004.62, 4293.85, ..., 4279.49, 4632.82, 4384.1 ],\n",
       "        [4327.69, 4006.67, 4295.38, ..., 4282.05, 4628.72, 4389.23],\n",
       "        [4328.72, 4011.79, 4296.41, ..., 4287.69, 4632.31, 4396.41],\n",
       "        ...,\n",
       "        [4326.15, 4010.77, 4276.41, ..., 4273.85, 4627.18, 4389.74],\n",
       "        [4326.15, 4011.28, 4276.92, ..., 4277.95, 4637.44, 4393.33],\n",
       "        [4326.15, 4010.77, 4272.82, ..., 4272.82, 4631.79, 4382.56]],\n",
       "\n",
       "       [[4327.69, 4006.67, 4295.38, ..., 4282.05, 4628.72, 4389.23],\n",
       "        [4328.72, 4011.79, 4296.41, ..., 4287.69, 4632.31, 4396.41],\n",
       "        [4326.15, 4011.79, 4292.31, ..., 4288.21, 4632.82, 4398.46],\n",
       "        ...,\n",
       "        [4326.15, 4011.28, 4276.92, ..., 4277.95, 4637.44, 4393.33],\n",
       "        [4326.15, 4010.77, 4272.82, ..., 4272.82, 4631.79, 4382.56],\n",
       "        [4316.92, 4002.56, 4259.49, ..., 4262.05, 4613.33, 4370.77]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[4293.85, 4005.13, 4262.56, ..., 4276.92, 4602.05, 4352.31],\n",
       "        [4298.97, 4006.67, 4261.03, ..., 4277.95, 4599.49, 4350.77],\n",
       "        [4296.92, 4006.15, 4264.1 , ..., 4278.97, 4606.67, 4351.28],\n",
       "        ...,\n",
       "        [4280.51, 3988.72, 4249.23, ..., 4271.28, 4595.38, 4343.08],\n",
       "        [4281.03, 3990.26, 4245.64, ..., 4269.23, 4593.33, 4340.51],\n",
       "        [4276.92, 3991.79, 4245.13, ..., 4259.49, 4590.26, 4333.33]],\n",
       "\n",
       "       [[4298.97, 4006.67, 4261.03, ..., 4277.95, 4599.49, 4350.77],\n",
       "        [4296.92, 4006.15, 4264.1 , ..., 4278.97, 4606.67, 4351.28],\n",
       "        [4289.23, 4003.08, 4263.59, ..., 4279.49, 4609.23, 4354.36],\n",
       "        ...,\n",
       "        [4281.03, 3990.26, 4245.64, ..., 4269.23, 4593.33, 4340.51],\n",
       "        [4276.92, 3991.79, 4245.13, ..., 4259.49, 4590.26, 4333.33],\n",
       "        [4277.44, 3990.77, 4246.67, ..., 4257.95, 4591.79, 4339.49]],\n",
       "\n",
       "       [[4296.92, 4006.15, 4264.1 , ..., 4278.97, 4606.67, 4351.28],\n",
       "        [4289.23, 4003.08, 4263.59, ..., 4279.49, 4609.23, 4354.36],\n",
       "        [4288.72, 3999.49, 4254.36, ..., 4281.03, 4605.13, 4351.79],\n",
       "        ...,\n",
       "        [4276.92, 3991.79, 4245.13, ..., 4259.49, 4590.26, 4333.33],\n",
       "        [4277.44, 3990.77, 4246.67, ..., 4257.95, 4591.79, 4339.49],\n",
       "        [4284.62, 3991.79, 4251.28, ..., 4267.18, 4596.41, 4350.77]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat1 = [[X[i+j] for i in range (10)]for j in range(len(df)-10)]\n",
    "X =np.array(dat1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(df[df.columns[14]],dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [[Y[i+j] for i in range (1)]for j in range(len(df)-10)]\n",
    "Y = np.array(target, dtype =int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11976, 10, 14)\n",
      "(2994, 10, 14)\n",
      "(11976, 10)\n",
      "(2994, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the LSTM Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM((1),batch_input_shape = (None,10,14),return_sequences = False,activation='relu'))\n",
    "model1.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1)                 64        \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11976 samples, validate on 2994 samples\n",
      "Epoch 1/50\n",
      "11976/11976 [==============================] - 2s 166us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 2/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 3/50\n",
      "11976/11976 [==============================] - 2s 131us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 4/50\n",
      "11976/11976 [==============================] - 2s 131us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 5/50\n",
      "11976/11976 [==============================] - 1s 121us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 6/50\n",
      "11976/11976 [==============================] - 1s 121us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 7/50\n",
      "11976/11976 [==============================] - 2s 148us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 8/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 9/50\n",
      "11976/11976 [==============================] - 1s 114us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 10/50\n",
      "11976/11976 [==============================] - 1s 118us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 11/50\n",
      "11976/11976 [==============================] - 1s 119us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 12/50\n",
      "11976/11976 [==============================] - 1s 122us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 13/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 14/50\n",
      "11976/11976 [==============================] - 1s 121us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 15/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 16/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 17/50\n",
      "11976/11976 [==============================] - 1s 121us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 18/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 19/50\n",
      "11976/11976 [==============================] - 1s 116us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 20/50\n",
      "11976/11976 [==============================] - 2s 129us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 21/50\n",
      "11976/11976 [==============================] - 2s 130us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 22/50\n",
      "11976/11976 [==============================] - 2s 130us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 23/50\n",
      "11976/11976 [==============================] - 1s 123us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 24/50\n",
      "11976/11976 [==============================] - 2s 129us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 25/50\n",
      "11976/11976 [==============================] - 2s 140us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 26/50\n",
      "11976/11976 [==============================] - 1s 123us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 27/50\n",
      "11976/11976 [==============================] - 1s 116us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 28/50\n",
      "11976/11976 [==============================] - 2s 130us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 29/50\n",
      "11976/11976 [==============================] - 1s 116us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 30/50\n",
      "11976/11976 [==============================] - 1s 121us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 31/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 32/50\n",
      "11976/11976 [==============================] - 1s 124us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 33/50\n",
      "11976/11976 [==============================] - 1s 120us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 34/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 35/50\n",
      "11976/11976 [==============================] - 1s 121us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 36/50\n",
      "11976/11976 [==============================] - 1s 119us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 37/50\n",
      "11976/11976 [==============================] - 2s 132us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 38/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 39/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 40/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 41/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 42/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 43/50\n",
      "11976/11976 [==============================] - 2s 131us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 44/50\n",
      "11976/11976 [==============================] - 1s 121us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 45/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 46/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 47/50\n",
      "11976/11976 [==============================] - 1s 115us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 48/50\n",
      "11976/11976 [==============================] - 2s 130us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 49/50\n",
      "11976/11976 [==============================] - 1s 123us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n",
      "Epoch 50/50\n",
      "11976/11976 [==============================] - 1s 116us/step - loss: 0.4490 - acc: 0.5510 - val_loss: 0.4462 - val_acc: 0.5538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23789489f98>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using LSTM Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1 = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994/2994 [==============================] - 0s 31us/step\n"
     ]
    }
   ],
   "source": [
    "eval1 = model1.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.44622578490313963\n",
      "Test accuracy: 0.5537742150968604\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', eval1[0])\n",
    "print('Test accuracy:', eval1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for LSTM Model 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [[Y[i+j] for i in range (10)]for j in range(len(df)-10)]\n",
    "Y = np.array(target, dtype =int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the LSTM Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM((10),batch_input_shape = (None,10,14),return_sequences = False))\n",
    "#model2.add(LSTM((1),return_sequences = False))\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10)                1000      \n",
      "=================================================================\n",
      "Total params: 1,000\n",
      "Trainable params: 1,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11976 samples, validate on 2994 samples\n",
      "Epoch 1/50\n",
      "11976/11976 [==============================] - 2s 173us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 2/50\n",
      "11976/11976 [==============================] - 2s 137us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 3/50\n",
      "11976/11976 [==============================] - 1s 124us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 4/50\n",
      "11976/11976 [==============================] - 2s 134us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 5/50\n",
      "11976/11976 [==============================] - 1s 124us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 6/50\n",
      "11976/11976 [==============================] - 1s 124us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 7/50\n",
      "11976/11976 [==============================] - 1s 124us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 8/50\n",
      "11976/11976 [==============================] - 1s 124us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 9/50\n",
      "11976/11976 [==============================] - 1s 124us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 10/50\n",
      "11976/11976 [==============================] - 1s 125us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 11/50\n",
      "11976/11976 [==============================] - 1s 125us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 12/50\n",
      "11976/11976 [==============================] - 1s 125us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 13/50\n",
      "11976/11976 [==============================] - 1s 125us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 14/50\n",
      "11976/11976 [==============================] - 1s 124us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 15/50\n",
      "11976/11976 [==============================] - 2s 125us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 16/50\n",
      "11976/11976 [==============================] - 1s 125us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 17/50\n",
      "11976/11976 [==============================] - 2s 125us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 18/50\n",
      "11976/11976 [==============================] - 1s 125us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 19/50\n",
      "11976/11976 [==============================] - 2s 142us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 20/50\n",
      "11976/11976 [==============================] - 2s 142us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 21/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 22/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 23/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 24/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 25/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 26/50\n",
      "11976/11976 [==============================] - 2s 126us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 27/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 28/50\n",
      "11976/11976 [==============================] - 2s 126us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 29/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 30/50\n",
      "11976/11976 [==============================] - 2s 126us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 31/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 32/50\n",
      "11976/11976 [==============================] - 2s 126us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 33/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 34/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 35/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 36/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 37/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 38/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 39/50\n",
      "11976/11976 [==============================] - 2s 127us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 40/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 41/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 42/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 43/50\n",
      "11976/11976 [==============================] - 2s 129us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 44/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 45/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 46/50\n",
      "11976/11976 [==============================] - 2s 129us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 47/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 48/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 49/50\n",
      "11976/11976 [==============================] - 2s 129us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n",
      "Epoch 50/50\n",
      "11976/11976 [==============================] - 2s 128us/step - loss: 0.4369 - acc: 9.1850e-04 - val_loss: 0.4448 - val_acc: 6.6800e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a30da3a9e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using LSTM Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2 = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.7615942, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.7615942, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.7615942, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [0.       , 0.7615942, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.7615942, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.7615942, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994/2994 [==============================] - 0s 33us/step\n"
     ]
    }
   ],
   "source": [
    "eval2 = model2.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.4448013137640281\n",
      "Test accuracy: 0.0006680026720106881\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', eval2[0])\n",
    "print('Test accuracy:', eval2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
